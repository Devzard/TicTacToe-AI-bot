{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\r\n",
    "from gym import spaces\r\n",
    "import numpy as np\r\n",
    "import heuristicBot\r\n",
    "import os\r\n",
    "from stable_baselines.bench import Monitor\r\n",
    "from stable_baselines.vec_env import DummyVecEnv"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1b0e4526e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mheuristicBot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbench\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mACER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macktr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mACKTR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mher\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines\\deepq\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMlpPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCnnPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLnMlpPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLnCnnPolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_train\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPrioritizedReplayBuffer\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines\\deepq\\policies.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDiscrete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Player representation : 1(X), 2(O)\r\n",
    "Game grid : a 3x3 numpy array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def grid_score(grid):\r\n",
    "    \"\"\"\r\n",
    "    Checks if the grid is completed.\r\n",
    "    If yes and it is a draw(returns 0) or win(returns 1)\r\n",
    "    else the game should continue(returns -1)\r\n",
    "    \"\"\"\r\n",
    "    if 0 not in grid:\r\n",
    "        return 0\r\n",
    "    rcno = [0, 1, 2]\r\n",
    "    # checking for rows and column condition\r\n",
    "    for i in rcno:\r\n",
    "        if grid[i, 0] == grid[i, 1] == grid[i, 2] != 0:\r\n",
    "            return 1\r\n",
    "        elif grid[0, i] == grid[1, i] == grid[2, i] != 0:\r\n",
    "            return 1\r\n",
    "    # checking for diagonals\r\n",
    "    if grid[0, 0] == grid[1, 1] == grid[2, 2] != 0:\r\n",
    "        return 1\r\n",
    "    elif grid[0, 2] == grid[1, 1] == grid[2, 0] != 0:\r\n",
    "        return 1\r\n",
    "    return -1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def mark_piece(grid, index, player):\r\n",
    "    \"\"\"\r\n",
    "    1. places a move by the RL agent\r\n",
    "    2. check if invalid\r\n",
    "    3. if not check if agent won or draw\r\n",
    "    4. if not place move by opponent\r\n",
    "    5. check if opponent won or draw\r\n",
    "    6. return respective code at appropiate step\r\n",
    "    returns -2:continue, -1:invalid move, \r\n",
    "            1:1 wins, 2:2 wins, 0:draw\r\n",
    "    \"\"\"\r\n",
    "    if grid[index] != 0:\r\n",
    "        return -1, grid\r\n",
    "    else:\r\n",
    "        grid[index] = player\r\n",
    "        score = ttt.gridScore(grid)\r\n",
    "        if score != -1 and score == 1:\r\n",
    "            return player, grid\r\n",
    "        elif score != -1:\r\n",
    "            return 0, grid\r\n",
    "        # opponent agent : a n-step-lookahead bot\r\n",
    "        available_moves = [(i, j) for i in range(3)\r\n",
    "                           for j in range(3) if grid[i, j] == 0]\r\n",
    "        opp_player = (player % 2) + 1\r\n",
    "        opp_move_idx = heuristicBot.nslAgent(\r\n",
    "            2, grid, available_moves, opp_player)\r\n",
    "        grid[opp_move_idx] = opp_player\r\n",
    "        score = ttt.gridScore(grid)\r\n",
    "        if score != -1 and score == 1:\r\n",
    "            return opp_player, grid\r\n",
    "        elif score != -1:\r\n",
    "            return 0, grid\r\n",
    "        return -2, grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Custom gym environment\r\n",
    "**Rewards**\r\n",
    "- 1 for winning\r\n",
    "- -1 for loosing\r\n",
    "- -10 for invalid move\r\n",
    "- 1/9 for everything else"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TicTacToeEnv(gym.Env):\r\n",
    "    def __init__(self):\r\n",
    "        \"\"\"\r\n",
    "        Define action and observation space\r\n",
    "        They must be gym.spaces objects\r\n",
    "        \"\"\"\r\n",
    "        super(TicTacToeEnv, self).__init__()\r\n",
    "        self.action_space = spaces.Discrete(9)\r\n",
    "        self.observation_space = spaces.Box(low=0, high=2, shape=(3,3), dtype=np.int)\r\n",
    "        self.reward_range = (-10, 1)\r\n",
    "        self.action_moves = [(i,j) for i in range(3) for j in range(3)]\r\n",
    "        self.player = 1\r\n",
    "        \r\n",
    "        # defined else stable baselines throws error\r\n",
    "        self.spec = None\r\n",
    "        self.metadata = None\r\n",
    "\r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        \"\"\"\r\n",
    "        Reset the state of the environment to an initial state\r\n",
    "        returns \r\n",
    "        eg.\r\n",
    "            return self.state\r\n",
    "        \"\"\"\r\n",
    "        self.grid = np.zeros((3, 3))\r\n",
    "\r\n",
    "        return self.grid\r\n",
    "\r\n",
    "\r\n",
    "    def step(self, action):\r\n",
    "        \"\"\"\r\n",
    "        Execute one time step within the environment\r\n",
    "        returns next state\r\n",
    "        eg. \r\n",
    "            modify state\r\n",
    "            return self.state, reward, done, info\r\n",
    "        \"\"\"\r\n",
    "        score, self.grid = mark_piece(self.grid, self.action_moves[action], self.player)\r\n",
    "\r\n",
    "        # reward\r\n",
    "        done = True\r\n",
    "        if score == -1:\r\n",
    "            reward = -10\r\n",
    "        elif score == 1:\r\n",
    "            reward = 1\r\n",
    "        elif score == 2:\r\n",
    "            reward = -1\r\n",
    "        elif score == -2:\r\n",
    "            done = False\r\n",
    "            reward = 1/9\r\n",
    "\r\n",
    "        # check if grid ended\r\n",
    "\r\n",
    "        # info for debugginh\r\n",
    "        info = {}\r\n",
    "        \r\n",
    "        return self.grid, reward, done, info\r\n",
    "\r\n",
    "\r\n",
    "    def render(self, mode='human', close=False):\r\n",
    "        # Render the environment to the screen\r\n",
    "        pass\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c92433add6838504b7902b5ec78188fe4df6a7e85695bf26bd386e93bc3b1798"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}